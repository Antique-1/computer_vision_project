1. 프로젝트 주제

이미지 식별 기술을 활용해 생활 쓰레기의 종류를 자동으로 판별하고, 분리수거 분류(플라스틱 / 유리 / 캔 / 종이 / 음식물 등)를 제안하는 컴퓨터비전 기반 분리수거 보조 시스템을 구현합니다.
목표는 스마트폰/카메라로 찍은 사진(혹은 영상)에서 쓰레기를 검출·분류하고, 사용자에게 어떤 분리수거함에 넣어야 하는지 알려주는 실용적인 파이프라인을 만드는 것입니다.

2. 개발 배경 및 목표

배경

도시 생활에서 분리수거 규칙이 지역별로 다르고, 사용자들이 올바르게 분리하지 못해 재활용 효율이 낮아지는 문제가 있음.

모바일 카메라와 경량화된 CV 모델 성능 향상으로 실시간 지원 서비스 구현이 현실화됨.

목표

사진(또는 영상 프레임)에서 쓰레기 객체를 검출(위치)하고, 객체별 카테고리를 높은 정확도로 예측.

예측 결과를 바탕으로 **권장 분리수거 타입(예: 플라스틱/종이/캔/유리/음식물/비닐 등)**과 간단한 처리(씻기 필요 여부 등)를 제안.

모바일·웹에서 사용 가능한 경량화된 배포(ON-DEVICE 또는 서버-API) 제공.

데이터셋·레이블링 파이프라인, 모델 학습·평가, 배포·UI까지의 엔드투엔드 구현.

3. 관련 문헌 및 기술 배경 (예시)

핵심 기술: 객체검출(Object Detection), 분할(Segmentation), 분류(Classification), 경량화(Quantization / Pruning), 데이터 증강

객체 검출/분할 주요 기법 (배경 지식)

Faster R-CNN / Mask R-CNN 계열: 높은 정확도의 인스턴스 분할·검출.

YOLO (v4/v5/v8 등), SSD, EfficientDet: 실시간 검출에 강점.

Segmentation (DeepLab, U-Net 변형): 음식물/부착물 등 경계가 모호한 객체에 유리.

모델 경량화/실시간 처리

지연·모바일 배포를 위해 MobileNet, EfficientNet-lite, YOLO-Nano 계열 고려.

양자화(PTQ/QAT)·지식증류·프루닝을 통해 모델 크기 축소.

데이터/라벨링

COCO / Pascal VOC 스타일의 bounding box 또는 COCO 인스턴스 세그멘테이션 포맷 권장.

클래스 불균형 해결을 위한 증강 기법(랜덤 컷페이스, MixUp, Mosaic 등).

(필요하면 특정 논문/아티클 링크로 참조 목록 정리 가능)

4. 선행 프로젝트 및 차별점

선행 예시

오픈 소스 재활용 분류 프로젝트(이미지 분류 중심)들 — 보통 단일 인스턴스 이미지를 전제로 함.

일부 앱은 사진 업로드 후 텍스트 기반 가이드를 제공하지만 높은 물체 검출 정확도/복수 객체 처리·현장 조건(조명·부분 가림)에 취약.

본 프로젝트의 차별점

다중 객체 검출 + 인스턴스 분할을 통해 복합 장면(여러 쓰레기, 겹침)에서도 정확히 분류.

분리수거 규칙 매핑 레이어(지역 설정에 따라 분류 결과를 재매핑) 제공.

해설(간단한 권장 처리법): 예) “플라스틱류 — 라벨 제거 후 압착 권장” 같은 추가 설명 자동 생성.

경량화된 모바일 배포 옵션과 서버 API 옵션을 모두 제공해 다양한 사용 시나리오 지원.

5. 모델 구현 계획 및 방향성
5.1 데이터 수집 및 전처리

데이터 소스: 공개 데이터셋 + 자체 촬영(다양한 조명·배경) + 크라우드소싱 레이블링

라벨링 스펙:

인스턴스 레벨: bounding box + category (+ 가능 시 segmentation mask)

카테고리 예시: 플라스틱병, 플라스틱용기, 비닐, 종이, 신문/종이박스, 유리병, 캔, 음식물, 기타

데이터 증강: 밝기·대비 변환, 회전·반사, 랜덤 크롭, CutMix/Mosaic(검출 모델용)

데이터 포맷: COCO JSON 권장 (bbox, segmentation, category_id 등)

5.2 모델 설계

옵션 A (정확도 우선)

Backbone: EfficientNet / ResNeXt

Head: Mask R-CNN (인스턴스 분할 포함)

옵션 B (실시간/모바일 우선)

경량형 세트: YOLOv8-nano / MobileNetV3 + SSD / EfficientDet-lite

이후 양자화(8-bit) 및 지식증류 적용

추가 모듈

후처리: NMS(Non-Max Suppression), 클래스별 임계값 튜닝

규칙 매핑: 지역별 분리수거 규칙 테이블 → 예측 매핑

해설 생성: 템플릿 기반 권장 문구 + 간단한 GPT 계열(선택사항)을 통한 문장 생성

5.3 학습·평가

손실/평가지표: mAP@0.5 / mAP@[0.5:0.95], 클래스별 Precision/Recall, IoU, F1

성능 목표(예시): mAP@0.5 ≥ 0.70(데스크탑 모델) / 모바일 모델 Precision ≥ 0.80(주요 5개 클래스)

교차검증: 지역·조명별 분포를 고려한 교차 검증

5.4 배포

서버 API (초기 개발):

REST API 입력: 이미지 업로드 → 출력: JSON {predictions:[{label, score, bbox, mask_url}], suggested_bin, explanation}

모바일/엣지:

ON-DEVICE: TensorFlow Lite / ONNX Runtime Mobile / CoreML (플랫폼별 변환 스크립트 포함)

모델 경량화(Quantize, Prune), 샘플 앱(안드/아이폰) 제공

웹 UI: Streamlit 또는 React 기반 데모 (카메라 실시간 피드/이미지 업로드, 결과 시각화)

5.5 유지보수 & 확장

피드백 루프: 사용자 신고/정정 데이터를 수집해 주기적으로 재학습

지역 규칙 확장: 국가/지자체별 룰셋을 외부 파일로 관리하여 동적으로 적용
